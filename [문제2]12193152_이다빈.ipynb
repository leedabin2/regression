{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFkMd1kUBhfON0wUzjNWTz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leedabin2/regression/blob/main/%5B%EB%AC%B8%EC%A0%9C2%5D12193152_%EC%9D%B4%EB%8B%A4%EB%B9%88.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[문제2] WDBC 데이터에 대하여 위의 분석을 반복하여 수행하시오."
      ],
      "metadata": {
        "id": "364pUD-ixA-u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPG-8nNbc-ww",
        "outputId": "7a0c5bb1-39f3-468b-c870-bbe0c51ea557"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "d = pd.read_csv('drive/MyDrive/data/WDBC.csv')\n",
        "d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "wYWXZGVddVK4",
        "outputId": "792268fb-c6ce-49f1-fd6f-9c34c02dad9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    diagnosis  radius1  texture1  perimeter1   area1  smoothness1  \\\n",
              "0           M    17.99     10.38      122.80  1001.0      0.11840   \n",
              "1           M    20.57     17.77      132.90  1326.0      0.08474   \n",
              "2           M    19.69     21.25      130.00  1203.0      0.10960   \n",
              "3           M    11.42     20.38       77.58   386.1      0.14250   \n",
              "4           M    20.29     14.34      135.10  1297.0      0.10030   \n",
              "..        ...      ...       ...         ...     ...          ...   \n",
              "564         M    21.56     22.39      142.00  1479.0      0.11100   \n",
              "565         M    20.13     28.25      131.20  1261.0      0.09780   \n",
              "566         M    16.60     28.08      108.30   858.1      0.08455   \n",
              "567         M    20.60     29.33      140.10  1265.0      0.11780   \n",
              "568         B     7.76     24.54       47.92   181.0      0.05263   \n",
              "\n",
              "     compactness1  concavity1  concave_pt1  symmetry1  ...  radius3  texture3  \\\n",
              "0         0.27760     0.30010      0.14710     0.2419  ...   25.380     17.33   \n",
              "1         0.07864     0.08690      0.07017     0.1812  ...   24.990     23.41   \n",
              "2         0.15990     0.19740      0.12790     0.2069  ...   23.570     25.53   \n",
              "3         0.28390     0.24140      0.10520     0.2597  ...   14.910     26.50   \n",
              "4         0.13280     0.19800      0.10430     0.1809  ...   22.540     16.67   \n",
              "..            ...         ...          ...        ...  ...      ...       ...   \n",
              "564       0.11590     0.24390      0.13890     0.1726  ...   25.450     26.40   \n",
              "565       0.10340     0.14400      0.09791     0.1752  ...   23.690     38.25   \n",
              "566       0.10230     0.09251      0.05302     0.1590  ...   18.980     34.12   \n",
              "567       0.27700     0.35140      0.15200     0.2397  ...   25.740     39.42   \n",
              "568       0.04362     0.00000      0.00000     0.1587  ...    9.456     30.37   \n",
              "\n",
              "     perimeter3   area3  smoothness3  compactness3  concavity3  concave_pt3  \\\n",
              "0        184.60  2019.0      0.16220       0.66560      0.7119       0.2654   \n",
              "1        158.80  1956.0      0.12380       0.18660      0.2416       0.1860   \n",
              "2        152.50  1709.0      0.14440       0.42450      0.4504       0.2430   \n",
              "3         98.87   567.7      0.20980       0.86630      0.6869       0.2575   \n",
              "4        152.20  1575.0      0.13740       0.20500      0.4000       0.1625   \n",
              "..          ...     ...          ...           ...         ...          ...   \n",
              "564      166.10  2027.0      0.14100       0.21130      0.4107       0.2216   \n",
              "565      155.00  1731.0      0.11660       0.19220      0.3215       0.1628   \n",
              "566      126.70  1124.0      0.11390       0.30940      0.3403       0.1418   \n",
              "567      184.60  1821.0      0.16500       0.86810      0.9387       0.2650   \n",
              "568       59.16   268.6      0.08996       0.06444      0.0000       0.0000   \n",
              "\n",
              "     symmetry3  fractal_dim3  \n",
              "0       0.4601       0.11890  \n",
              "1       0.2750       0.08902  \n",
              "2       0.3613       0.08758  \n",
              "3       0.6638       0.17300  \n",
              "4       0.2364       0.07678  \n",
              "..         ...           ...  \n",
              "564     0.2060       0.07115  \n",
              "565     0.2572       0.06637  \n",
              "566     0.2218       0.07820  \n",
              "567     0.4087       0.12400  \n",
              "568     0.2871       0.07039  \n",
              "\n",
              "[569 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-341859d9-67ff-47e9-8eb5-d5e8790e9af6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius1</th>\n",
              "      <th>texture1</th>\n",
              "      <th>perimeter1</th>\n",
              "      <th>area1</th>\n",
              "      <th>smoothness1</th>\n",
              "      <th>compactness1</th>\n",
              "      <th>concavity1</th>\n",
              "      <th>concave_pt1</th>\n",
              "      <th>symmetry1</th>\n",
              "      <th>...</th>\n",
              "      <th>radius3</th>\n",
              "      <th>texture3</th>\n",
              "      <th>perimeter3</th>\n",
              "      <th>area3</th>\n",
              "      <th>smoothness3</th>\n",
              "      <th>compactness3</th>\n",
              "      <th>concavity3</th>\n",
              "      <th>concave_pt3</th>\n",
              "      <th>symmetry3</th>\n",
              "      <th>fractal_dim3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>...</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>...</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>...</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>...</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>...</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>M</td>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>...</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>M</td>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>...</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>M</td>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>...</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>M</td>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>...</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>B</td>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>...</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-341859d9-67ff-47e9-8eb5-d5e8790e9af6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-341859d9-67ff-47e9-8eb5-d5e8790e9af6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-341859d9-67ff-47e9-8eb5-d5e8790e9af6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "smp = pd.get_dummies(d, drop_first=True) # 범주형 데이터를 숫자형으로 바꾸는 더미 사용 \n",
        "smp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "puX2WBxKdnfB",
        "outputId": "9189b255-59e1-4004-849f-63625489c18b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     radius1  texture1  perimeter1   area1  smoothness1  compactness1  \\\n",
              "0      17.99     10.38      122.80  1001.0      0.11840       0.27760   \n",
              "1      20.57     17.77      132.90  1326.0      0.08474       0.07864   \n",
              "2      19.69     21.25      130.00  1203.0      0.10960       0.15990   \n",
              "3      11.42     20.38       77.58   386.1      0.14250       0.28390   \n",
              "4      20.29     14.34      135.10  1297.0      0.10030       0.13280   \n",
              "..       ...       ...         ...     ...          ...           ...   \n",
              "564    21.56     22.39      142.00  1479.0      0.11100       0.11590   \n",
              "565    20.13     28.25      131.20  1261.0      0.09780       0.10340   \n",
              "566    16.60     28.08      108.30   858.1      0.08455       0.10230   \n",
              "567    20.60     29.33      140.10  1265.0      0.11780       0.27700   \n",
              "568     7.76     24.54       47.92   181.0      0.05263       0.04362   \n",
              "\n",
              "     concavity1  concave_pt1  symmetry1  fractal_dim1  ...  texture3  \\\n",
              "0       0.30010      0.14710     0.2419       0.07871  ...     17.33   \n",
              "1       0.08690      0.07017     0.1812       0.05667  ...     23.41   \n",
              "2       0.19740      0.12790     0.2069       0.05999  ...     25.53   \n",
              "3       0.24140      0.10520     0.2597       0.09744  ...     26.50   \n",
              "4       0.19800      0.10430     0.1809       0.05883  ...     16.67   \n",
              "..          ...          ...        ...           ...  ...       ...   \n",
              "564     0.24390      0.13890     0.1726       0.05623  ...     26.40   \n",
              "565     0.14400      0.09791     0.1752       0.05533  ...     38.25   \n",
              "566     0.09251      0.05302     0.1590       0.05648  ...     34.12   \n",
              "567     0.35140      0.15200     0.2397       0.07016  ...     39.42   \n",
              "568     0.00000      0.00000     0.1587       0.05884  ...     30.37   \n",
              "\n",
              "     perimeter3   area3  smoothness3  compactness3  concavity3  concave_pt3  \\\n",
              "0        184.60  2019.0      0.16220       0.66560      0.7119       0.2654   \n",
              "1        158.80  1956.0      0.12380       0.18660      0.2416       0.1860   \n",
              "2        152.50  1709.0      0.14440       0.42450      0.4504       0.2430   \n",
              "3         98.87   567.7      0.20980       0.86630      0.6869       0.2575   \n",
              "4        152.20  1575.0      0.13740       0.20500      0.4000       0.1625   \n",
              "..          ...     ...          ...           ...         ...          ...   \n",
              "564      166.10  2027.0      0.14100       0.21130      0.4107       0.2216   \n",
              "565      155.00  1731.0      0.11660       0.19220      0.3215       0.1628   \n",
              "566      126.70  1124.0      0.11390       0.30940      0.3403       0.1418   \n",
              "567      184.60  1821.0      0.16500       0.86810      0.9387       0.2650   \n",
              "568       59.16   268.6      0.08996       0.06444      0.0000       0.0000   \n",
              "\n",
              "     symmetry3  fractal_dim3  diagnosis_M  \n",
              "0       0.4601       0.11890            1  \n",
              "1       0.2750       0.08902            1  \n",
              "2       0.3613       0.08758            1  \n",
              "3       0.6638       0.17300            1  \n",
              "4       0.2364       0.07678            1  \n",
              "..         ...           ...          ...  \n",
              "564     0.2060       0.07115            1  \n",
              "565     0.2572       0.06637            1  \n",
              "566     0.2218       0.07820            1  \n",
              "567     0.4087       0.12400            1  \n",
              "568     0.2871       0.07039            0  \n",
              "\n",
              "[569 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-47ba4603-106b-4b8c-aa29-b7222773331f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius1</th>\n",
              "      <th>texture1</th>\n",
              "      <th>perimeter1</th>\n",
              "      <th>area1</th>\n",
              "      <th>smoothness1</th>\n",
              "      <th>compactness1</th>\n",
              "      <th>concavity1</th>\n",
              "      <th>concave_pt1</th>\n",
              "      <th>symmetry1</th>\n",
              "      <th>fractal_dim1</th>\n",
              "      <th>...</th>\n",
              "      <th>texture3</th>\n",
              "      <th>perimeter3</th>\n",
              "      <th>area3</th>\n",
              "      <th>smoothness3</th>\n",
              "      <th>compactness3</th>\n",
              "      <th>concavity3</th>\n",
              "      <th>concave_pt3</th>\n",
              "      <th>symmetry3</th>\n",
              "      <th>fractal_dim3</th>\n",
              "      <th>diagnosis_M</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>...</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>...</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>...</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>...</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>...</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47ba4603-106b-4b8c-aa29-b7222773331f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-47ba4603-106b-4b8c-aa29-b7222773331f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-47ba4603-106b-4b8c-aa29-b7222773331f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = smp.iloc[:,1:-2] # 설명변수\n",
        "y = smp.iloc[:,-1]# 목표변수\n",
        "y.value_counts(normalize=True)\n",
        "\n",
        "# 1 : m , 0 : b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKxrU5wGeZfT",
        "outputId": "716415dd-34c2-4042-8f0b-b41bc6bd75af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.627417\n",
              "1    0.372583\n",
              "Name: diagnosis_M, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "의사결정나무, xgboost 성능 비교"
      ],
      "metadata": {
        "id": "C5WzDO_kdzRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score"
      ],
      "metadata": {
        "id": "3DHV598od38H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 의사결정나무\n",
        "for d in range(2,11): # depth를 10까지 올리면 어떻게 되는지 확인\n",
        "  clf_tr = DecisionTreeClassifier(max_depth=d)\n",
        "  score_t = cross_validate(clf_tr,X,y,cv=5,return_train_score=True)\n",
        "  print(\"train: %.3f test: %.3f\" % (score_t['train_score'].mean(),score_t['test_score'].mean()))\n",
        "  # 평가데이터는 감소하거나 유지된다. 반면 학습데이터는 depth의 깊이가 증가할수록 높아지고 있다. "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDx24blZj5zm",
        "outputId": "cabde05d-7c3e-4949-e265-4d374d499221"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: 0.953 test: 0.928\n",
            "train: 0.974 test: 0.916\n",
            "train: 0.987 test: 0.930\n",
            "train: 0.992 test: 0.926\n",
            "train: 0.996 test: 0.928\n",
            "train: 0.999 test: 0.916\n",
            "train: 1.000 test: 0.919\n",
            "train: 1.000 test: 0.923\n",
            "train: 1.000 test: 0.916\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# xgboost \n",
        "import xgboost as xgb \n",
        "for d in range(2,11): # depth를 10까지 올리면 어떻게 되는지 확인\n",
        "  clf_xgb =xgb.XGBClassifier(max_depth=d)\n",
        "  score = cross_validate(clf_xgb,X,y,cv=5,return_train_score=True)\n",
        "  print(\"train: %.3f test: %.3f\" % (score['train_score'].mean(),score['test_score'].mean()))\n",
        "# 학습데이터는 1.000으로 성능이 좋으나, 평가데이터는 감소하거나 유지되는 경향을 보이고 있다. "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXfOq9qRkXWY",
        "outputId": "a3164990-7f32-4899-a064-da912e6fe0ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: 1.000 test: 0.974\n",
            "train: 1.000 test: 0.974\n",
            "train: 1.000 test: 0.974\n",
            "train: 1.000 test: 0.972\n",
            "train: 1.000 test: 0.972\n",
            "train: 1.000 test: 0.972\n",
            "train: 1.000 test: 0.972\n",
            "train: 1.000 test: 0.972\n",
            "train: 1.000 test: 0.972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "결과만 봤을 때 xgboost 모델의 평가 성능과 학습 성능이 모두 트리 모델보다 높음을 알 수 있다. 그러나 과적합할 가능성이 있다."
      ],
      "metadata": {
        "id": "WxzTg_2drPF1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5-fold cross_validation"
      ],
      "metadata": {
        "id": "CXYytz_Preje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "import xgboost as xgb\n",
        "\n",
        "clf_t = DecisionTreeClassifier(max_depth=5) # 의사결정나무 모델을 초기화, max_depth = 5 설정\n",
        "clf_r = LogisticRegression(max_iter=1000)\n",
        "clf_xgb = xgb.XGBClassifier(max_depth=5)\n",
        "\n",
        "\n",
        "score_t = cross_validate(clf_t, X,y, cv=5, return_train_score=True) # 의사결정나무 모델에 대한 5-fold 교차 검증을 수행\n",
        "score_r = cross_validate(clf_r,X,y, cv=5,  return_train_score=True) # 로지스틱회귀분석 모델에 대한 5-fold 교차 검증을 수행\n",
        "score_xgb = cross_validate(clf_xgb,X,y,cv=5, return_train_score=True) # xgboost 모델에 대한 5-fold 교차 검증을 수행"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjyKfMS3rj_D",
        "outputId": "59eec509-6dae-4cf1-8e0e-b783f2769192"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in score_t.items(): # tree\n",
        "    print(\"%s : %.3f\" %(k, v.mean()))\n",
        "# 평가데이터 성능은 0.919로 평균정도 높다고 볼 수 있음\n",
        "# 학습데이터 성능은 0.991로 모델의 적합도가 높음"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qs0Qncvsr5ov",
        "outputId": "239cf7b1-8473-4695-f4b8-605562d5e841"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fit_time : 0.009\n",
            "score_time : 0.002\n",
            "test_score : 0.919\n",
            "train_score : 0.991\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in score_r.items(): # 로지스틱회귀분석\n",
        "    print(\"%s : %.3f\" %(k, v.mean()))\n",
        "# 학습데이터와 평가데이터 모두 0.95로 모델의 적합도가 높음"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTe0k6Pbr_Ai",
        "outputId": "bc7398fb-1b2f-458d-c227-99c1854620d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fit_time : 0.372\n",
            "score_time : 0.004\n",
            "test_score : 0.953\n",
            "train_score : 0.958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in score_xgb.items(): # xgboodst 평가성능비교 \n",
        "    print(\"%s : %.3f\" %(k, v.mean()))\n",
        "# 학습데이터 성능은 1.000로 모델의 적합도가 높으나 이는 모델이 과적합 가능성이 있음을 암시\n",
        "# 평가데이터 성능은 0.972로 평균정도 높다고 볼 수 있음"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_PBoVH1sKUz",
        "outputId": "3f1818d6-17ee-4a1d-afaf-ad1a65667ed1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fit_time : 0.116\n",
            "score_time : 0.004\n",
            "test_score : 0.972\n",
            "train_score : 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "전체적으로 xgboost모델이 평가,학습데이터 성능이 다른 모델보다 우수함"
      ],
      "metadata": {
        "id": "Vmn0JKmMsUEg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10-fold cross_validation"
      ],
      "metadata": {
        "id": "YpVIxTmvsdNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "import xgboost as xgb\n",
        "\n",
        "clf_t = DecisionTreeClassifier(max_depth=10) # 의사결정나무 모델을 초기화, max_depth = 10 설정\n",
        "clf_r = LogisticRegression(max_iter=1000)\n",
        "clf_xgb = xgb.XGBClassifier(max_depth=10)\n",
        "\n",
        "\n",
        "score_t = cross_validate(clf_t, X,y, cv=10, return_train_score=True) # 의사결정나무 모델에 대한 10-fold 교차 검증을 수행\n",
        "score_r = cross_validate(clf_r, X,y, cv=10,  return_train_score=True) # 로지스틱회귀분석 모델에 대한 10-fold 교차 검증을 수행\n",
        "score_xgb = cross_validate(clf_xgb,X,y,cv=10, return_train_score=True) # xgboost 모델에 대한 10-fold 교차 검증을 수행"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGinbMm_sgDq",
        "outputId": "67e37a5c-b582-4c54-9e90-e79ccde385c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in score_t.items(): # tree\n",
        "    print(\"%s : %.3f\" %(k, v.mean()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nViQAFEwsoPS",
        "outputId": "0267ec2c-ca72-4109-fb82-88e649eb9fd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fit_time : 0.011\n",
            "score_time : 0.002\n",
            "test_score : 0.914\n",
            "train_score : 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in score_r.items(): # 로지스틱회귀분석\n",
        "    print(\"%s : %.3f\" %(k, v.mean()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIkqqlFLsp2J",
        "outputId": "42cf5450-f8ea-4249-c968-1b74c61130f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fit_time : 0.298\n",
            "score_time : 0.005\n",
            "test_score : 0.949\n",
            "train_score : 0.957\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in score_xgb.items(): # xgboost\n",
        "    print(\"%s : %.3f\" %(k, v.mean()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWGfW1G_srth",
        "outputId": "c3640ff4-0a23-41c5-a609-155c1393db7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fit_time : 0.116\n",
            "score_time : 0.005\n",
            "test_score : 0.975\n",
            "train_score : 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " * 10-fold cross-validation은 각 10개의 폴드에서 테스트 세트의 크기가 더 작아지기 때문에 모델의 성능 평가는 평가데이터에 대해 정확한 측정을 할 수 있으나, 테스트 세트의 크기가 작아져서 평가 데이터에 대한 일반화 능력을 저하시킬 수 있다.\n",
        "\n",
        " * 5-fold cross-validation과 10-fold cross-validation은 테스트 세트의 크기에 차이가 있기 때문에 성능 평가 결과의 차이가 있을 수 있다. 따라서 데이터셋의 크기와 모델의 복잡성에 따라 적절한 교차 검증 방법을 선택해야 한다."
      ],
      "metadata": {
        "id": "hu9YbQQ3tlrj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 설명변수 5개 선택 후 3가지 예측 모형의 성능 비교\n",
        "-10-fold cross_validation"
      ],
      "metadata": {
        "id": "WhFPqRwruOl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sel_X = pd.DataFrame({\n",
        "    'radius2': smp['radius2'],\n",
        "    'texture3': smp['texture3'],\n",
        "    'area2': smp['area2'],\n",
        "    'concave_pt3': smp['concave_pt3'],\n",
        "    'radius3': smp['radius3'],\n",
        "}) # 5개 선택변수\n",
        "sel_y = smp.iloc[:,-1]# 목표변수"
      ],
      "metadata": {
        "id": "VwFnrpKzuZXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "import xgboost as xgb\n",
        "\n",
        "clf_t = DecisionTreeClassifier(max_depth=10) # 의사결정나무 모델을 초기화, max_depth = 10 설정\n",
        "clf_r = LogisticRegression(max_iter=1000)\n",
        "clf_xgb = xgb.XGBClassifier(max_depth=10)\n",
        "\n",
        "\n",
        "score_t = cross_validate(clf_t, sel_X, sel_y, cv=10, return_train_score=True) # 의사결정나무 모델에 대한 10-fold 교차 검증을 수행\n",
        "score_r = cross_validate(clf_r, sel_X, sel_y, cv=10,  return_train_score=True) # 로지스틱회귀분석 모델에 대한 10-fold 교차 검증을 수행\n",
        "score_xgb = cross_validate(clf_xgb, sel_X, sel_y,cv=10, return_train_score=True) # xgboost 모델에 대한 10-fold 교차 검증을 수행"
      ],
      "metadata": {
        "id": "wzoPznP7vF0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in score_t.items(): # tree\n",
        "    print(\"%s : %.3f\" %(k, v.mean()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azN3xI_3vyJa",
        "outputId": "29cce7c8-cc2e-4ac1-d916-c0878ede7d17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fit_time : 0.004\n",
            "score_time : 0.002\n",
            "test_score : 0.937\n",
            "train_score : 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in score_r.items(): # 로지스틱회귀분석\n",
        "    print(\"%s : %.3f\" %(k, v.mean()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEZrcn8Ev0Fb",
        "outputId": "c5a731df-2f03-44ad-af4c-9d48dc58f3d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fit_time : 0.014\n",
            "score_time : 0.002\n",
            "test_score : 0.940\n",
            "train_score : 0.940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in score_xgb.items(): # xgboost\n",
        "    print(\"%s : %.3f\" %(k, v.mean()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoYhU9PAv147",
        "outputId": "df4fbfbf-feb7-4cc0-d6e6-5bc1e2962e13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fit_time : 0.050\n",
            "score_time : 0.004\n",
            "test_score : 0.951\n",
            "train_score : 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* xgboost 모델의 평가 데이터 성능이 0.95로 다른 모델보다 조금 더 높음을 알 수 있다. \n",
        "* 그러나 XGBoost는 학습 시간과 예측 시간이 상대적으로 길며, 학습 데이터에 과적합될 가능성이 있다. 따라서 시간적인 요소와 모델의 안정성을 고려한 모델을 선택해야 한다. \n"
      ],
      "metadata": {
        "id": "oTCtOEWQv61T"
      }
    }
  ]
}